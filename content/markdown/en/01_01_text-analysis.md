---
title: Text Analysis
author: Hennie Brugman
type: page
publication_date: 22-03-2022
meta_description:
meta_keyword:
summary: We have extensive experience with publishing different kinds of digital scholarly text collections. These include literary text editions, correspondence catalogues, as well as historical manuscripts and linguistic collections.
---
We have extensive experience with publishing different kinds of digital scholarly text collections. These include literary text editions, correspondence catalogues, as well as historical manuscripts and linguistic collections. The collections we publish are usually complemented by us with descriptive metadata, page images and other types of enrichments such as links to structured data and user annotations.

In particular, we offer researchers many ways to carry out complex searches — for example by using 'fuzzy' text patterns, finding semantically related passages or by filtering texts on the basis of structured data such as the persons or places mentioned in a text. We can also provide the necessary know-how and software to allow project teams to edit and visualize their text collections, to publish them on online, and to deposit them in a certified digital repository to ensure their long term preservation and access.

All of our text based projects make use of the open source [text repository](https://github.com/knaw-huc/textrepo) we have developed in-house at the Humanities Cluster. The software acts as a backend repository to store and index corpora with metadata and versions. An application such as a web front-end or editor can make use of the text repository's API to read, update, and delete texts, as well as to explore or search documents. In particular, much like the [IIIF Canvas standard](https://iiif.io), this enables the retrieval and annotation of text passages, irrespective of their original text format.

### Contact

[Hennie Brugman](mailto:hennie.brugman@di.huc.knaw.nl), Lead Developer for Team Text ([Research Gate](https://www.researchgate.net/profile/Hennie-Brugman), [LinkedIn](https://nl.linkedin.com/in/hennie-brugman-8327369), [Pure](https://pure.knaw.nl/portal/en/persons/h-brugman))

### Related Projects

+ what did we contribute to each of these projects?

- [Nederlab](https://www.nederlab.nl) (Meertens Institute) is an online portal for historical research on Dutch language, literature and culture. On the site, researchers can search, view, and analyse tens of thousands of Dutch texts.
- [Republic](https://republic.huygens.knaw.nl) (Huygens Institute) stands for REsolutions PUBLished In a Computational environment. The goal of the project is to make all of the manuscript and printed resolutions of the Dutch States General (1576-1796) freely available online as full texts and page images.
- [Globalise](https://globalise.huygens.knaw.nl) (huygens Institute). The NWO Groot funded Globalise project will develop an online infrastructure that unlocks the key series of VOC reports (c. 4.7M pages) for advanced new research methods. Contribution: The project uses our text repository infrastructure as a hub to synchronise the collection, enrichment, and curation of historical text transcriptions.
- [SHEBANQ](https://shebanq.ancient-data.org) (CLARIN-NL project) is a website to fire linguistic queries on the Hebrew Bible and publish them there. Thee underlying data is available as [dataset](https://github.com/ETCBC/BHSA) in text-fabric format.
- CLARIAH (specifiek voor Maarten’s werk, core shared annotation services)
- tba

// screenshot from one of the above projects to be inserted here

### Software and Data

+ what did we contribute to each of these resources?
+ Docere ownership - current status?

- [Text Repository](https://github.com/knaw-huc/textrepo) (KNAW Humanities Cluster) is a  backend repository system to store and index text corpora with metadata and versions.
- [LaMachine](https://proycon.github.io/LaMachine) (Radboud University Nijmegen) is a unified software distribution for Natural Language Processing. It integrates numerous open-source NLP tools, programming libraries, web-services and web-applications in a single Virtual Research Environment that can be installed on a wide variety of machines.
- [analiticcl](https://github.com/proycon/analiticcl)(KNAW Humanities Cluster) is an approximate string matching or fuzzy-matching system for spelling correction, normalisation or post-OCR correction.
- [Docere](https://github.com/knaw-huc/docere) (Gijsjan Brouwer) is a flexible and customisable digital (scholarly) edition publishing platform.
- [Text-Fabric](https://annotation.github.io/text-fabric/tf/index.html) (Dirk Roorda) is machinery to process text corpora plus (large) amounts of annotations. It serves as a bridge between researcher and data scientist.
- tba

### Publications and Presentations

- iets van Maarten over LaMachine, MvG’s video over analiticcl
- Nederlab paper
- Republic paper van Marijn
- een ppt over untanngle?
- tba
- tba
- tba
